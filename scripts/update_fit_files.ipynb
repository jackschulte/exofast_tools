{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06574cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9ae52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fit(path, prior_filename, pro_filename, check_slope=False, median_filename=None):\n",
    "    '''\n",
    "    Reads the fit directory to update lightcurve indices and check slope significance. Warning: this will overwrite the prior and procedures files!\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Path to the directory containing the prior file and lightcurve files.\n",
    "    prior_filename : str\n",
    "        Name of the prior file to be updated.\n",
    "    pro_filename : str\n",
    "        Name of the procedures file to be updated.\n",
    "    check_slope : bool, optional\n",
    "        If True, checks the median file to see if the slope parameter is consistent with zero and removes it from the prior and procedures files if so. Default is False.\n",
    "    median_filename : str, optional\n",
    "        Name of the median file to be checked if check_slope is True.\n",
    "    -----------\n",
    "    Returns:\n",
    "    None\n",
    "    -----------\n",
    "\n",
    "    '''\n",
    "\n",
    "    lc_list = sorted([f for f in os.listdir(path) if f.startswith('n2') and f.endswith('.dat')])\n",
    "    tess_indices = [i for i, f in enumerate(lc_list) if 'TESS' in f]\n",
    "\n",
    "    with open(os.path.join(path, prior_filename), 'r') as f:\n",
    "        priorfile_old = f.read()\n",
    "        priorfile_new = priorfile_old\n",
    "\n",
    "    # find and replace dilute indices\n",
    "    for index in tess_indices:\n",
    "        if index == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # update the indices for the starting values for dilute, variance, and f0, one-by-one\n",
    "            # I include the format of the dilute line in the patterns for variance and f0 to ensure that only the old indices are replaced\n",
    "            priorfile_new = re.sub(r'(variance_\\d+)( -?\\d+.\\d+\\ndilute_\\d+ -?\\d+)', f'variance_{index}' + r'\\2', priorfile_new, count=1)\n",
    "            priorfile_new = re.sub(r'(dilute_\\d+ -?\\d+.\\d+\\n)(f0_\\d+ )', r'\\1' + f'f0_{index} ', priorfile_new, count=1)\n",
    "            priorfile_new = re.sub(r'dilute_\\d+ -?\\d+.\\d+', f'dilute_{index} dilute_0 0', priorfile_new, count=1) # do dilute last b/c of above patterns\n",
    "    if 0 in tess_indices:\n",
    "        priorfile_new = re.sub(r'dilute ', 'dilute_0 ', priorfile_new) # update the first dilute parameter\n",
    "        priorfile_new = re.sub(r'variance ', 'variance_0 ', priorfile_new) # update the first variance parameter\n",
    "        priorfile_new = re.sub(r'f0 ', 'f0_0 ', priorfile_new) # update the first f0 parameter\n",
    "\n",
    "    if check_slope:\n",
    "        # read median file and check if slope is consistent with zero\n",
    "        with open(f'{path}/fitresults/{median_filename}', 'r') as f:\n",
    "            medianfile = f.read()\n",
    "            slope_params = re.findall(r'slope_0,(-?\\d*\\.\\d+),(\\d*\\.\\d+),(\\d*\\.\\d+)', medianfile) # format: parameter, median, upper_err, lower_err\n",
    "            median_slope = float(slope_params[0][0])\n",
    "            median_slope_upp_err = float(slope_params[0][1])\n",
    "            median_slope_low_err = float(slope_params[0][2])\n",
    "\n",
    "            if (median_slope - median_slope_low_err <= 0) and (median_slope + median_slope_upp_err >= 0):\n",
    "                remove_slope = True\n",
    "            else:\n",
    "                remove_slope = False\n",
    "            \n",
    "        if remove_slope:\n",
    "            # remove slope starting value from prior file\n",
    "            priorfile_new = re.sub(r'slope -?\\d+.\\d+', '', priorfile_new)\n",
    "            \n",
    "    \n",
    "    with open(os.path.join(path, prior_filename), 'w') as f:\n",
    "        f.write(priorfile_new)\n",
    "\n",
    "    ## Update procedures file\n",
    "\n",
    "    # initialize lists\n",
    "    exptimes = []\n",
    "    ninterp = []\n",
    "    fitdilute = []\n",
    "\n",
    "    for i in range(len(lc_list)):\n",
    "        if i in tess_indices:\n",
    "            exptime_s = re.findall(r'(\\d+)sunbinned.dat', lc_list[i])\n",
    "            exptime_min = int(exptime_s[0]) / 60\n",
    "            exptimes.append(int(exptime_min))\n",
    "            if exptime_min == 30:\n",
    "                ninterp.append(10)\n",
    "            elif exptime_min == 10:\n",
    "                ninterp.append(4)\n",
    "            else:\n",
    "                ninterp.append(1)\n",
    "            fitdilute.append(1)\n",
    "        else:\n",
    "            exptimes.append(1)\n",
    "            ninterp.append(1)\n",
    "            fitdilute.append(0)\n",
    "\n",
    "    with open(os.path.join(path, pro_filename), 'r') as f:\n",
    "        pro_file_old = f.read()\n",
    "\n",
    "    pro_file_new = re.sub(r'exptime=\\[.*\\]', f'exptime={exptimes}', pro_file_old)\n",
    "    pro_file_new = re.sub(r'ninterp=\\[.*\\]', f'ninterp={ninterp}', pro_file_new)\n",
    "    pro_file_new = re.sub(r'fitdilute=\\[.*\\]', f'fitdilute={fitdilute}', pro_file_new)\n",
    "\n",
    "    if check_slope:\n",
    "        if remove_slope:\n",
    "            pro_file_new = re.sub(r'/fitslope', '', pro_file_new)\n",
    "            print('Slope removed from fit as it is consistent with zero.')\n",
    "        else:\n",
    "            print(f'Slope retained in fit as it appears to be significant (median: {median_slope}, +{median_slope_upp_err}, -{median_slope_low_err}).')\n",
    "\n",
    "    with open(os.path.join(path, pro_filename), 'w') as f:\n",
    "        f.write(pro_file_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98accf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_slurm_file(path, slurm_filename, time_days, ncpu):\n",
    "    with open(os.path.join(path, slurm_filename), 'r') as f:\n",
    "        slurm_file_old = f.read()\n",
    "    \n",
    "    # Set time limit for SLURM job\n",
    "    time_minutes = time_days * 24 * 60\n",
    "    slurm_file_new = re.sub(r'#SBATCH --time=\\d+', f'#SBATCH --time={int(time_minutes)}', slurm_file_old)\n",
    "\n",
    "    # Set time limit for EXOFASTv2\n",
    "    time_seconds = (time_minutes - 360) * 60 # EXOFAST ends 6 hrs before SLURM to allow for transit time calculations\n",
    "    slurm_file_new = re.sub(r'maxtime=\\d+', f'maxtime={int(time_seconds)}', slurm_file_new)\n",
    "\n",
    "    if 'makepdfs.sh' not in slurm_file_new:\n",
    "        # Append a few new lines at the bottom to turn postscripts into pdfs\n",
    "        slurm_file_new += \"\\n\\n# Turn postscripts into pdfs\\n\"\n",
    "        slurm_file_new += \"cd fitresults\\n\"\n",
    "        slurm_file_new += \"makepdfs.sh\\n\"\n",
    "        slurm_file_new += \"cd ..\\n\"\n",
    "\n",
    "    # Set number of CPUs\n",
    "    slurm_file_new = re.sub(r'#SBATCH --cpus-per-task=\\d+', f'#SBATCH --cpus-per-task={ncpu}', slurm_file_new) # for SLURM\n",
    "    slurm_file_new = re.sub(r'nthread=\\d+', f'nthread={ncpu}', slurm_file_new) # for EXOFASTv2\n",
    "\n",
    "    with open(os.path.join(path, slurm_filename), 'w') as f:\n",
    "        f.write(slurm_file_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524e1cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope retained in fit as it appears to be significant (median: 0.068, +0.066, -0.066).\n"
     ]
    }
   ],
   "source": [
    "path = '/mnt/research/Exoplanet_Lab/jack/Global_Fits/meep3/toi5479'\n",
    "prior_filename = '67444896.priors.2'\n",
    "pro_filename = 'fittoi5479.pro'\n",
    "median_filename = '67444896.median.csv'\n",
    "\n",
    "update_fit(path, prior_filename, pro_filename, check_slope=True, median_filename=median_filename)\n",
    "update_slurm_file(path, 'SLURM_toi5479.sb', time_days=4, ncpu=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f4dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_hpcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
